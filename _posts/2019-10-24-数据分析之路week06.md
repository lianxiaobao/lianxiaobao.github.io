---
layout:     post
title:      数据分析之路week06
subtitle:   彩票预测，选号分析
date:       2019-10-18
author:     BY xiaobao(微信：Bao1697047283)
header-img: img/post-bg-mi1.jpg
catalog: true
tags:
    - blog
    - 数据分析
    - python
---

# 彩票那点事儿

![](https://tva1.sinaimg.cn/large/006y8mN6ly1g89o5ogad2j30jo0xsmyb.jpg)
最近朋友的一个小需求突然让我有了这个小想法，这个需求也能玩一玩数据分析，当学习demo
代码都已上传GitHub[点击查看](https://github.com/lianxiaobao/dataset/tree/master)

## 数据分析基本意义

– 数据分析是指用适当的统计方法对收集来的大量第一手数据（资料）和第二手数据（资料）进行分析，以求最大化地开发数据资料的功能，发挥数据的作用。是为了提取有用信息和形成结论而对数据加以详细研究和概况总结的过程。
– 在实用中，数据分析可帮助人们作出判断，以便采取适当行动。

首先讲一下数据分析的整个思路：
## 数据分析的步骤


![](https://tva1.sinaimg.cn/large/006y8mN6ly1g89osu3n78j31jm0li40g.jpg)

### 确定一下目的

1、每个号码出现的次数是一样的吗？

2、往期数据能预测下一期的号码吗？

3、连号有什么规律吗？

### 数据准备
爬取往期的彩票数据，经过对比后发现这家数据完整也好爬，对比过[重庆时时彩](![](https://tva1.sinaimg.cn/large/006y8mN6ly1g89qlgdzarj31ep0u0h0n.jpg))他居然支持直接导出数据。。。不开心。。没有爬数据的快感。。。



![](https://tva1.sinaimg.cn/large/006y8mN6ly1g89qr9m33ej30uu08caae.jpg)


最后选择
<http://datachart.500.com/dlt/history/history.shtml>

#### 分析页面：

 * 进入f12输入0查找 查看相应规律爬取往期数据

![](https://tva1.sinaimg.cn/large/006y8mN6ly1g89o0w9js4j31h40u0ahs.jpg)

  
 * 对页面进一步获取html元素，分析页面组成

![](https://tva1.sinaimg.cn/large/006y8mN6ly1g89qlgdzarj31ep0u0h0n.jpg)

*  python脚本 爬取历史数据

```python

import requests
from lxml import etree
import pandas as pd


def get_ten_years_data(url):
    headers={
        'accept-encoding': 'gzip, deflate, br',
        'accept-language': 'zh-CN,zh;q=0.9,en;q=0.8',
        'User-Agent':'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_14_3) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/77.0.3865.120 Safari/537.36'

    }

    response=requests.get(url, headers=headers)
    if response.status_code == 200:
        return response.text
    return None


url="http://datachart.500.com/dlt/history/newinc/history.php?start=00001&end=19119";
# print(get_ten_years_data(url))
data = etree.HTML(get_ten_years_data(url))
# print(data)
trs = data.xpath('//tr')
k=0
for tr in trs:
    k=k+1
print(k)


requests =[]
for i in range(1, k-3):

    result_num = data.xpath('//*[@id="tdata"]/tr['+str(i)+']/td[1]/text()')[0]
    print(result_num, end='\t')
    resrult_bef1 = data.xpath('//*[@id="tdata"]/tr['+str(i)+']/td[2]/text()')[0]
    print(resrult_bef1, end='\t')
    resrult_bef2 = data.xpath('//*[@id="tdata"]/tr['+str(i)+']/td[3]/text()')[0]
    print(resrult_bef2, end='\t')
    resrult_bef3 = data.xpath('//*[@id="tdata"]/tr['+str(i)+']/td[4]/text()')[0]
    print(resrult_bef3, end='\t')
    resrult_bef4 = data.xpath('//*[@id="tdata"]/tr['+str(i)+']/td[5]/text()')[0]
    print(resrult_bef4, end='\t')
    resrult_bef5 = data.xpath('//*[@id="tdata"]/tr['+str(i)+']/td[6]/text()')[0]
    print(resrult_bef5, end='\t')
    resrult_beh1 = data.xpath('//*[@id="tdata"]/tr['+str(i)+']/td[7]/text()')[0]
    print(resrult_beh1, end='\t')
    resrult_beh2 = data.xpath('//*[@id="tdata"]/tr['+str(i)+']/td[8]/text()')[0]
    print(resrult_beh2, end='\t')
    prize_pool = data.xpath('//*[@id="tdata"]/tr['+str(i)+']/td[9]/text()')[0]
    print(prize_pool, end='\t')
    first_prize_size = data.xpath('//*[@id="tdata"]/tr[' + str(i) + ']/td[10]/text()')[0]
    print(first_prize_size, end='\t')
    first_prize = data.xpath('//*[@id="tdata"]/tr[' + str(i) + ']/td[11]/text()')[0]
    print(first_prize, end='\t')
    second_prize_size = data.xpath('//*[@id="tdata"]/tr[' + str(i) + ']/td[12]/text()')[0]
    print(second_prize_size, end='\t')
    second_prize = data.xpath('//*[@id="tdata"]/tr[' + str(i) + ']/td[13]/text()')[0]
    print(second_prize, end='\t')
    total_bet_amount = data.xpath('//*[@id="tdata"]/tr['+str(i)+']/td[14]/text()')[0]
    print(total_bet_amount, end='\t')
    result_day = data.xpath('//*[@id="tdata"]/tr['+str(i)+']/td[15]/text()')[0]
    print(result_day, end='\t')


    print(i)

    pos ={
        'result_num': result_num,
        'resrult_bef1': resrult_bef1,
        'resrult_bef2': resrult_bef2,
        'resrult_bef3': resrult_bef3,
        'resrult_bef4': resrult_bef4,
        'resrult_bef5': resrult_bef5,
        'resrult_beh1': resrult_beh1,
        'resrult_beh2': resrult_beh2,
        'prize_pool': prize_pool,
        'first_prize_size': first_prize_size,
        'first_prize': first_prize,
        'second_prize_size': second_prize_size,
        'second_prize': second_prize,
        'total_bet_amount': total_bet_amount,
        'result_day': result_day,
    }
    requests.append(pos)
    # print(requests)

df = pd.DataFrame(requests)
df.to_csv('/Users/lianxiaobao/lianxiaobao/bigdatabook/daletou.csv', mode='a')

```

* 将数据保存到了我的superset中展示方便日后多维分析展示，该表格当然没有做处理只是`select *..`

![](https://tva1.sinaimg.cn/large/006y8mN6ly1g89szi21cjj31qd0u0jy1.jpg)


### 能预测下一期吗？


* 导包

```python
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.linear_model import LinearRegression
from sklearn.metrics import r2_score
import statsmodels.api as sm
```

* 概览数据


```python
data = pd.read_csv('/Users/lianxiaobao/lianxiaobao/bigdatabook/daletou.csv')
data.head()
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Unnamed: 0</th>
      <th>first_prize</th>
      <th>first_prize_size</th>
      <th>prize_pool</th>
      <th>resrult_bef1</th>
      <th>resrult_bef2</th>
      <th>resrult_bef3</th>
      <th>resrult_bef4</th>
      <th>resrult_bef5</th>
      <th>resrult_beh1</th>
      <th>resrult_beh2</th>
      <th>result_day</th>
      <th>result_num</th>
      <th>second_prize</th>
      <th>second_prize_size</th>
      <th>total_bet_amount</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0</td>
      <td>10,000,000</td>
      <td>4</td>
      <td>2,450,995,411</td>
      <td>3</td>
      <td>6</td>
      <td>9</td>
      <td>23</td>
      <td>34</td>
      <td>2</td>
      <td>11</td>
      <td>2019/10/19</td>
      <td>19119</td>
      <td>611,893</td>
      <td>83</td>
      <td>296,906,555</td>
    </tr>
    <tr>
      <th>1</th>
      <td>1</td>
      <td>10,000,000</td>
      <td>2</td>
      <td>2,505,219,109</td>
      <td>2</td>
      <td>3</td>
      <td>13</td>
      <td>19</td>
      <td>26</td>
      <td>2</td>
      <td>3</td>
      <td>2019/10/16</td>
      <td>19118</td>
      <td>406,469</td>
      <td>101</td>
      <td>272,734,633</td>
    </tr>
    <tr>
      <th>2</th>
      <td>2</td>
      <td>10,000,000</td>
      <td>4</td>
      <td>2,510,705,016</td>
      <td>1</td>
      <td>18</td>
      <td>21</td>
      <td>25</td>
      <td>35</td>
      <td>7</td>
      <td>8</td>
      <td>2019/10/14</td>
      <td>19117</td>
      <td>806,808</td>
      <td>66</td>
      <td>271,077,215</td>
    </tr>
    <tr>
      <th>3</th>
      <td>3</td>
      <td>10,000,000</td>
      <td>4</td>
      <td>2,540,591,129</td>
      <td>2</td>
      <td>10</td>
      <td>16</td>
      <td>21</td>
      <td>23</td>
      <td>2</td>
      <td>12</td>
      <td>2019/10/12</td>
      <td>19116</td>
      <td>770,679</td>
      <td>87</td>
      <td>297,819,968</td>
    </tr>
    <tr>
      <th>4</th>
      <td>4</td>
      <td>10,000,000</td>
      <td>6</td>
      <td>2,576,114,778</td>
      <td>1</td>
      <td>18</td>
      <td>21</td>
      <td>28</td>
      <td>32</td>
      <td>5</td>
      <td>12</td>
      <td>2019/10/9</td>
      <td>19115</td>
      <td>498,979</td>
      <td>105</td>
      <td>286,493,206</td>
    </tr>
  </tbody>
</table>
</div>


```python
data.columns
```




    Index(['Unnamed: 0', 'first_prize', 'first_prize_size', 'prize_pool',
           'resrult_bef1', 'resrult_bef2', 'resrult_bef3', 'resrult_bef4',
           'resrult_bef5', 'resrult_beh1', 'resrult_beh2', 'result_day',
           'result_num', 'second_prize', 'second_prize_size', 'total_bet_amount'],
          dtype='object')




* 简单线性回归
 
   * 模型

     * 对于简单的线性回归，只考虑次数的影响。在直接进入建模之前，看一下数据的样子。

     * 使用matplotlib 一个Python绘图库来制作散点图。

>前区的一个球可能出现的数字和次数的散点图  

```python
plt.figure(figsize=(16, 8))
plt.scatter(
    data['result_day'],
    data['resrult_bef1'],
    c='black'
)
plt.xlabel("daletou open day(d)")
plt.ylabel("bef1 (num)")
plt.show()
```


![](https://tva1.sinaimg.cn/large/006y8mN6ly1g89srhpbm8j30q80dft8s.jpg)


>后区的一个球可能出现的数字和次数的散点图  

```python
plt.figure(figsize=(16, 8))
plt.scatter(
    data['result_day'],
    data['resrult_beh1'],
    c='black'
)
plt.xlabel("daletou open day(d)")
plt.ylabel("bef1 (num)")
plt.show()
```


![](https://tva1.sinaimg.cn/large/006y8mN6ly1g89srhaeigj30q80dfdfu.jpg)


#### 生成简单回归线图形方法一


* 假设次数和号码数有关联
	* 生成近似函数 


```python
X = data['Unnamed: 0'].values.reshape(-1,1)
y = data['resrult_bef1'].values.reshape(-1,1)
reg = LinearRegression()
reg.fit(X, y)
print(reg.coef_[0][0])
print(reg.intercept_[0])
```

    0.0007193466601768446
    5.6506553914011715



```python
print("The huigui model is: Y = {:.6} + {:.6}X".format(reg.intercept_[0], reg.coef_[0][0]))
```

    The huigui model is: Y = 5.65066 + 0.000719347X


* 生成简单回归线图形

```python
predictions = reg.predict(X)
plt.figure(figsize=(16, 8))
plt.scatter(
    data['Unnamed: 0'],
    data['resrult_bef1'],
    c='black'
)
plt.plot(
    data['Unnamed: 0'],
    predictions,
    c='blue',
    linewidth=4
)
plt.xlabel("daletou open day(d)")
plt.ylabel("bef1 (num)")
plt.show()
```


![](https://tva1.sinaimg.cn/large/006y8mN6ly1g89srguaizj30q80dfq31.jpg)


#### 生成简单回归线图形方法二


```python
X = data['Unnamed: 0']
y = data['resrult_bef1']
X2 = sm.add_constant(X)
model = sm.OLS(y, X2)
result = model.fit()

result.params
```




    const         5.650655
    Unnamed: 0    0.000719
    dtype: float64




```python
print(result2.summary())
```

                                OLS Regression Results                            
    ==============================================================================
    Dep. Variable:           resrult_bef1   R-squared:                       0.006
    Model:                            OLS   Adj. R-squared:                  0.006
    Method:                 Least Squares   F-statistic:                     11.54
    Date:                Thu, 24 Oct 2019   Prob (F-statistic):           0.000696
    Time:                        19:20:31   Log-Likelihood:                -5781.4
    No. Observations:                1901   AIC:                         1.157e+04
    Df Residuals:                    1899   BIC:                         1.158e+04
    Df Model:                           1                                         
    Covariance Type:            nonrobust                                         
    ==============================================================================
                     coef    std err          t      P>|t|      [0.025      0.975]
    ------------------------------------------------------------------------------
    const          5.6507      0.232     24.319      0.000       5.195       6.106
    Unnamed: 0     0.0007      0.000      3.397      0.001       0.000       0.001
    ==============================================================================
    Omnibus:                      388.306   Durbin-Watson:                   2.003
    Prob(Omnibus):                  0.000   Jarque-Bera (JB):              695.987
    Skew:                           1.275   Prob(JB):                    7.38e-152
    Kurtosis:                       4.510   Cond. No.                     2.19e+03
    ==============================================================================
    
    Warnings:
    [1] Standard Errors assume that the covariance matrix of the errors is correctly specified.
    [2] The condition number is large, 2.19e+03. This might indicate that there are
    strong multicollinearity or other numerical problems.



```python
# 中间偏下的 coef 列就是计算出的回归系数。
# 我们还可以将拟合结果画出来。先调用拟合结果的 fittedvalues 得到拟合的 y 值。
y_fitted = result.fittedvalues

# 然后使用 matplotlib.pyploft 画图。首先设定图轴，图片大小为 16×8。
fig, ax = plt.subplots(figsize=(16,8))

# 画出原数据，图像为圆点，默认颜色为蓝。
ax.plot(X, y, 'o', label='data')

# 画出拟合数据，图像为红色带点间断线。
ax.plot(X, y_fitted, 'r--.',label='OLS')

# 放置注解。
ax.legend(loc='best')
```



![](https://tva1.sinaimg.cn/large/006y8mN6ly1g89srgey4cj30pu0d1t8s.jpg)


#### 生成简单回归线图形方法三

* 简单暴力直接上excle神器

1、首先你要有数据分析功能
 
 ![](https://tva1.sinaimg.cn/large/006y8mN6ly1g89ts7rzm1j31180u0asr.jpg)
 
 ![](https://tva1.sinaimg.cn/large/006y8mN6ly1g89ts8y00xj31d10u0wj2.jpg)
 
2、开始happy

* 1


![](https://tva1.sinaimg.cn/large/006y8mN6ly1g89tvfefahj31w00qan3m.jpg)

* 2

![](https://tva1.sinaimg.cn/large/006y8mN6ly1g89tz3uf48j31nt0u07c3.jpg)

* 3

![](https://tva1.sinaimg.cn/large/006y8mN6ly1g89tz6jbpgj31bc0u0tmc.jpg)


#### 回归参数解释


```
                            OLS Regression Results                            
==============================================================================
Dep. Variable:           resrult_bef1   R-squared:                       0.006
Model:                            OLS   Adj. R-squared:                  0.006
Method:                 Least Squares   F-statistic:                     11.54
Date:                Thu, 24 Oct 2019   Prob (F-statistic):           0.000696
Time:                        19:20:31   Log-Likelihood:                -5781.4
No. Observations:                1901   AIC:                         1.157e+04
Df Residuals:                    1899   BIC:                         1.158e+04
Df Model:                           1                                         
Covariance Type:            nonrobust                                         
==============================================================================
                 coef    std err          t      P>|t|      [0.025      0.975]
------------------------------------------------------------------------------
const          5.6507      0.232     24.319      0.000       5.195       6.106
Unnamed: 0     0.0007      0.000      3.397      0.001       0.000       0.001
==============================================================================
Omnibus:                      388.306   Durbin-Watson:                   2.003
Prob(Omnibus):                  0.000   Jarque-Bera (JB):              695.987
Skew:                           1.275   Prob(JB):                    7.38e-152
Kurtosis:                       4.510   Cond. No.                     2.19e+03
==============================================================================

Warnings:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.
[2] The condition number is large, 2.19e+03. This might indicate that there are
strong multicollinearity or other numerical problems.
```



* 左边：（模型背景描述）
	* Dep.Variable: 输出变量的名称
	* Model :模型名称
	* Method: 方法 其中 Least Squares 表示最小二乘法
	* Date： 日期
	* Time： 时间
	* No.Observations: 样本数目
	* Df Residuals : 残差自由度 (观测数No.Observations - (参数数目Df Model+1常数))

       * –残差代表的是实际观察值与估计值的差
   * Df Model: 模型参数个数，相当于输入的X的元素个数

* 右边：（模型质量描述）（需要参考判断的数据）
	* R- squared : 可决系数，用来判断估计的准确性，范围在 [0,1] 约接近1 ，说明对y的解释能力越强，拟合越好

	* Adj-R- squared: 通过样本数量与模型数量对R-squared进行修正，奥卡姆剃刀原理，避免描述冗杂
	* F-statistic : 衡量拟合的显著性, 重要程度。模型的均方误差除以残差的均方误差,值越大,H0 越不可能
	* Prob(F-statistic): 当prob（F-statistic）<α时，表示拒绝原假设，即认为模型是显著的；
		* 当prob（F-statistic）>α时，表示接受原假设，即认为模型不是显著的

	* Log likelihood （对数似然比LLR） :(很多说法是值越大，说明模型拟合的较好)(但有待考察,似然比服从统计量,大于卡方临界值拒绝原假设)
通过最大似然估计参数的选取的拟合性
（Davidson 与MacKinnon(1993)年说：对于线性回归模型，不管它误差是不是正态分布，都不需要过问LM，W，LLR，因为这些信息已被F检验所含有）
	* AIC: AIC可以表示为： AIC=2k-2ln(L) 其中：k是参数的数量，L是似然函数。 衡量拟合优良性,选择AIC 最小的模型, 引入了惩罚项,避免参数过多,过拟合
	* BIC: 贝叶斯信息准则 BIC=kln(n)-2ln(L) ,BIC相比AIC在大数据量时对模型参数惩罚得更多，导致BIC更倾向于选择参数少的简单模型。

* 下半部分:(模型描述)
	* coef: 系数 const表示常数项
	* std err :系数估计的基本标准误差
	* t : t 统计值,衡量系数统计显著程度的指标
	* P>|t| : 系数= 0的零假设为真的P值。如果它小于置信水平，通常为0.05，则表明该术语与响应之间存在统计上显着的关系。度的指标
[0.025,0.975]: 95％置信区间的下限和上限值

	* Omnibus :属于一种统计测验,测试一组数据中已解释方差是否显著大于未解释方差,但omnibus不显著,模型也可能存在合法的显著影响, 比如两个变量中有一个不显著,即便另一个显著.通常用于对比
	* Prob(Omnibus):将上面的统计数据变成概率
	* Durbin-Watson : 残差是否符合正态分布,在2左右说明是服从正态分布的,偏离2太远,解释能力受影响
是否自相关, 受到前后影响 ,与表中上限进行比较,如果D>上限 不存在相关性 .
D<下限 存在正相关性,在上下限之间,无法得出结论
	* Skewness: 偏度, 关于平均值的数据对称性的度量。正态分布误差应是关于平均值对称的分布。
	* Kurtosis: 峰度, 分布形状的量度,比较接近均值与远离均值的数据量 如果大于三,说明峰的形状比较陡峭,形状较尖
正态分布的峰度（系数）为常数3，均匀分布的峰度（系数）为常数1.8
	* Jarque-Bera(JB) : Jarque–Bera检验是对样本数据是否具有符合正态分布的偏度和峰度的拟合优度的检验。
其统计测试结果总是非负的。如果结果远大于零，则表示数据不具有正态分布。
	* Prob(JB): 上面统计量的概率形式
	* Cond. No :多重共线性测试(如果多个参数,这些参数是否相互关联)

**从简单线性图可以看出一个球的预测都很随机，从图中也可以看出从数据发描述性统计更能体现数据特征 想全中 太难了**

...未完待续


